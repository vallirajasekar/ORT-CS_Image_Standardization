{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOw1Riy9to3Tz05k4YsXRCR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vallirajasekar/ORT-CS_Image_Standardization/blob/main/ORT_CS_Image_Standardization_BasicTesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fCSOuePZ8N-s"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name=\"Computer_Vision.zip\"\n",
        "\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSI9e9rp8lbe",
        "outputId": "926f240e-6566-42b7-9674-0b08ee09b1a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed for reproducibility\n",
        "tf.random.set_seed(42)\n"
      ],
      "metadata": {
        "id": "TsPd2S518sA-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths to your training and testing data\n",
        "train_data_dir = \"/content/Computer_Vision/Base_Data /training\"\n",
        "test_data_dir = \"/content/Computer_Vision/Base_Data /testing\"\n"
      ],
      "metadata": {
        "id": "u2slUX2J8yGM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the parameters for data preprocessing and augmentation\n",
        "batch_size = 32\n",
        "image_size = (150, 150)  # Adjust this based on your image dimensions\n"
      ],
      "metadata": {
        "id": "W6qLQQqX9EIt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data generators for training and testing data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'  # Assuming two classes: happy and not_happy\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO0wFd099FkR",
        "outputId": "104e1124-2d41-4ef2-858a-2d66d02ab4bc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16 images belonging to 2 classes.\n",
            "Found 9 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification output\n",
        "])\n"
      ],
      "metadata": {
        "id": "rn6fWwBL9Ok8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "atwTDrGD9TeI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10  # Adjust the number of epochs based on your needs\n",
        "model.fit(train_generator, epochs=epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdzHuxhg9YHv",
        "outputId": "6763538b-6059-4762-ddc1-5a53e237c373"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.7239 - accuracy: 0.3125\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4.0129 - accuracy: 0.6875\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.7036 - accuracy: 0.6875\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6870 - accuracy: 0.4375\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.8807 - accuracy: 0.3750\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5832 - accuracy: 0.6875\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4926 - accuracy: 0.6875\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5556 - accuracy: 0.6875\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4581 - accuracy: 0.6875\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.3820 - accuracy: 0.7500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f59ef8cdea0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the testing data\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(\"Test loss:\", loss)\n",
        "print(\"Test accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLiPve0B9eNt",
        "outputId": "4542c1bf-67e8-406e-ce56-1e11b534bf9a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 297ms/step - loss: 1.1313 - accuracy: 0.5556\n",
            "Test loss: 1.1312847137451172\n",
            "Test accuracy: 0.5555555820465088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image_label(image_path):\n",
        "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=image_size)\n",
        "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    image = image / 255.0  # Normalize the image\n",
        "    image = tf.expand_dims(image, 0)  # Add batch dimension\n",
        "    prediction = model.predict(image)\n",
        "    if prediction[0] >= 0.5:\n",
        "        return \"happy\"\n",
        "    else:\n",
        "        return \"not_happy\"\n"
      ],
      "metadata": {
        "id": "l1RVo2219jNM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_image_path = \"/content/Computer_Vision/download (1).jpeg\"\n",
        "predicted_label = predict_image_label(new_image_path)\n",
        "print(\"Predicted label:\", predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6Z9i6Wk9tH0",
        "outputId": "3b8381d5-db0e-42d7-fea6-12a339c06940"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicted label: not_happy\n"
          ]
        }
      ]
    }
  ]
}